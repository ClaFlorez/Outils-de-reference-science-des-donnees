# âœ‚ï¸ Ã‰tape 3 : SÃ©paration des donnÃ©es
```python
# SÃ©paration des donnÃ©es
train_size = int(0.8 * len(X_data))
X_train, X_test = X_data[:train_size], X_data[train_size:]
y_train, y_test = y_data[:train_size], y_data[train_size:]

```
## ğŸ” Objectif de la sÃ©paration

La sÃ©paration des donnÃ©es en ensembles d'entraÃ®nement et de test est une Ã©tape cruciale dans le processus d'apprentissage automatique. Elle nous permet d'Ã©valuer la performance du modÃ¨le sur des donnÃ©es qu'il n'a jamais vues pendant l'entraÃ®nement.

## ğŸ“Š Code de sÃ©paration

### Explication dÃ©taillÃ©e

1. **Calcul de la taille de l'ensemble d'entraÃ®nement** :
   - `train_size = int(0.8 * len(X_data))` : Nous utilisons 80% des donnÃ©es pour l'entraÃ®nement.
   - La fonction `int()` assure que nous avons un nombre entier d'Ã©chantillons.

2. **SÃ©paration des features (X)** :
   - `X_train = X_data[:train_size]` : Les premiers 80% des donnÃ©es vont dans l'ensemble d'entraÃ®nement.
   - `X_test = X_data[train_size:]` : Les 20% restants vont dans l'ensemble de test.

3. **SÃ©paration des labels (y)** :
   - `y_train = y_data[:train_size]` : Les labels correspondant aux 80% des donnÃ©es d'entraÃ®nement.
   - `y_test = y_data[train_size:]` : Les labels correspondant aux 20% des donnÃ©es de test.

## ğŸ§  Pourquoi cette approche ?

- **SimplicitÃ©** : Cette mÃ©thode de sÃ©paration est simple et rapide Ã  mettre en Å“uvre.
- **PrÃ©servation de l'ordre** : Si l'ordre des donnÃ©es est important (par exemple, pour des sÃ©ries temporelles), cette mÃ©thode le prÃ©serve.
- **ReproductibilitÃ©** : En utilisant un indice fixe, nous obtenons toujours la mÃªme sÃ©paration.

## âš ï¸ Points d'attention

- **ReprÃ©sentativitÃ©** : Cette mÃ©thode suppose que les donnÃ©es sont dÃ©jÃ  mÃ©langÃ©es alÃ©atoirement. Si ce n'est pas le cas, il faudrait d'abord les mÃ©langer.
- **Stratification** : Pour les problÃ¨mes de classification, il peut Ãªtre prÃ©fÃ©rable d'utiliser une sÃ©paration stratifiÃ©e pour maintenir la distribution des classes.

## ğŸ”„ Alternatives possibles

- **train_test_split de scikit-learn** : Pour une sÃ©paration plus avancÃ©e, notamment avec stratification.
- **random_split de PyTorch** : Pour une sÃ©paration alÃ©atoire directement sur les datasets PyTorch.

## ğŸ“ˆ Prochaines Ã©tapes

AprÃ¨s cette sÃ©paration, nous sommes prÃªts Ã  crÃ©er nos datasets PyTorch et Ã  commencer l'entraÃ®nement de notre modÃ¨le.


