# ğŸ§  Ã‰tape 5 : DÃ©finition du modÃ¨le

## ğŸ¯ Objectif de la dÃ©finition du modÃ¨le

La dÃ©finition du modÃ¨le est une Ã©tape cruciale dans le processus d'apprentissage profond. Elle dÃ©termine l'architecture du rÃ©seau neuronal qui sera utilisÃ©e pour apprendre Ã  partir de nos donnÃ©es et faire des prÃ©dictions.

## ğŸ’» Code de dÃ©finition du modÃ¨le

```python
# DÃ©finition du modÃ¨le
class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(3, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )

    def forward(self, x):
        return self.model(x)

model = NeuralNetwork()
```


## ğŸ” Explication dÃ©taillÃ©e

### 1. DÃ©finition de la classe NeuralNetwork
```python
# DÃ©finition du modÃ¨le
class NeuralNetwork(nn.Module):
```
- HÃ©rite de `nn.Module`, la classe de base pour tous les modules PyTorch.
- Permet de dÃ©finir une architecture de rÃ©seau neuronal personnalisÃ©e.

### 2. MÃ©thode d'initialisation
```python
  def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(3, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
```
- `super(NeuralNetwork, self).__init__()` : Initialise la classe parent `nn.Module`.
- `nn.Sequential` : CrÃ©e une sÃ©quence de couches qui seront appliquÃ©es dans l'ordre.
- Architecture du rÃ©seau :
  1. PremiÃ¨re couche linÃ©aire : 3 entrÃ©es -> 64 neurones
  2. Fonction d'activation ReLU
  3. DeuxiÃ¨me couche linÃ©aire : 64 -> 32 neurones
  4. Fonction d'activation ReLU
  5. Couche de sortie : 32 -> 1 neurone (pour la rÃ©gression)

### 3. MÃ©thode forward
```python
 def forward(self, x):
 return self.model(x)
```

- DÃ©finit comment les donnÃ©es traversent le rÃ©seau.
- Simplement passe l'entrÃ©e `x` Ã  travers le modÃ¨le sÃ©quentiel dÃ©fini.

### 4. Instanciation du modÃ¨le
```python
model = NeuralNetwork()
```
- CrÃ©e une instance de notre classe `NeuralNetwork`.

## ğŸ§  Pourquoi cette architecture ?

- **Couches linÃ©aires** : Permettent au modÃ¨le d'apprendre des relations complexes entre les entrÃ©es et la sortie.
- **ReLU** : Fonction d'activation non linÃ©aire qui aide Ã  capturer des relations non linÃ©aires dans les donnÃ©es.
- **Taille dÃ©croissante** : 64 -> 32 -> 1 permet une rÃ©duction progressive de la dimensionnalitÃ©.
- **Couche de sortie unique** : AdaptÃ©e Ã  notre problÃ¨me de rÃ©gression (prÃ©diction d'une seule valeur).

## âš ï¸ Points d'attention

- **Nombre de paramÃ¨tres** : Cette architecture a suffisamment de paramÃ¨tres pour apprendre, sans Ãªtre trop complexe.
- **Risque de surapprentissage** : Surveillez les performances sur l'ensemble de test.
- **Initialisation des poids** : PyTorch initialise automatiquement les poids, mais cela peut Ãªtre personnalisÃ© si nÃ©cessaire.

## ğŸ”„ Alternatives possibles

- **Couches supplÃ©mentaires** : Pour des problÃ¨mes plus complexes.
- **Dropout** : Peut Ãªtre ajoutÃ© pour rÃ©duire le surapprentissage.
- **Batch Normalization** : Pour stabiliser l'apprentissage dans les rÃ©seaux plus profonds.

## ğŸ“ˆ Prochaines Ã©tapes

Avec notre modÃ¨le dÃ©fini, nous sommes prÃªts Ã  configurer l'optimiseur et la fonction de coÃ»t pour commencer l'entraÃ®nement.








